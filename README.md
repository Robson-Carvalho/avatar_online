# ğŸ§ª Testes de Software â€” ValidaÃ§Ã£o do Sistema DistribuÃ­do

## 1. Objetivo dos Testes

Os testes de software tÃªm como objetivo **avaliar a robustez e a justiÃ§a da soluÃ§Ã£o distribuÃ­da**, garantindo que:
- O **algoritmo de consenso Raft** mantenha a consistÃªncia entre os nÃ³s durante operaÃ§Ãµes concorrentes;
- O sistema se comporte corretamente em **situaÃ§Ãµes de falha e redirecionamento de requisiÃ§Ãµes**;
- O desempenho sob carga seja **aceitÃ¡vel** (tempo de resposta, taxa de sucesso, throughput).

Esses testes tambÃ©m foram projetados para **reproduzir cenÃ¡rios reais de uso**, simulando mÃºltiplos usuÃ¡rios executando operaÃ§Ãµes simultÃ¢neas como criaÃ§Ã£o de contas, abertura de pacotes e atualizaÃ§Ã£o de baralhos.

---

## 2. Ambiente de Teste

Os testes foram executados em um ambiente **Dockerizado**, composto por trÃªs nÃ³s Raft independentes, cada um com sua prÃ³pria instÃ¢ncia de banco de dados PostgreSQL.

### Estrutura dos ContÃªineres

| Componente | DescriÃ§Ã£o |
|-------------|------------|
| `avatar-node1` | NÃ³ lÃ­der (coordena a replicaÃ§Ã£o dos logs) |
| `avatar-node2` | NÃ³ seguidor (replica e valida as entradas) |
| `avatar-node3` | NÃ³ seguidor (replica e valida as entradas) |
| `postgres-nodeX` | Banco de dados dedicado a cada nÃ³ |

Cada contÃªiner Ã© definido em seu respectivo `docker-compose.yml`, com **endereÃ§os fixos** configurados para permitir a comunicaÃ§Ã£o entre os nÃ³s.

---

## 3. ExecuÃ§Ã£o dos Testes

Os testes foram implementados em **Python**, utilizando mÃºltiplas threads para simular usuÃ¡rios concorrentes interagindo com o sistema.

### Principais Scripts

| Script | DescriÃ§Ã£o |
|---------|------------|
| `stress_createUser_test.py` | Simula mÃºltiplos usuÃ¡rios realizando cadastro simultÃ¢neo. Avalia o redirecionamento automÃ¡tico de requisiÃ§Ãµes para o lÃ­der e a consistÃªncia dos dados cadastrados. |
| `stress_openPack_test.py` | Realiza a abertura de pacotes de cartas simultaneamente, validando se o estado do jogo Ã© corretamente replicado em todos os nÃ³s. |
| `stress_deckUpdate_test.py` | Testa a atualizaÃ§Ã£o de baralhos dos jogadores, verificando se as mudanÃ§as sÃ£o aplicadas de forma consistente apÃ³s o commit no lÃ­der. |
| `stress_tradeCard_test.py` | Teste a troca de cartas entre jogadores, verificando se as mudanÃ§as foram aplicadas corretamente entre os nÃ³s |

---

## 4. ExecuÃ§Ã£o dos Testes Manualmente

Para rodar os testes individualmente:

```bash
# Subir o cluster distribuÃ­do
docker-compose -f docker-compose-develop.yml up --build

# Executar o teste de criaÃ§Ã£o de usuÃ¡rios
python3 stress_createUser_test.py

# Executar o teste de abertura de pacotes
python3 stress_openPack_test.py

# Executar o teste de atualizaÃ§Ã£o de baralhos
python3 stress_deckUpdate_test.py

# Executar o teste de troca de cartas
python3 stress_tradeCard_test.py
```

Os resultados dos testes podem ser vistos em arquivos .json da pasta /backend/stress_test para melhor analise e visualizaÃ§Ã£o. 
## 5. Resultados Esperados

Durante a execuÃ§Ã£o dos testes, o sistema deve:
- Detectar automaticamente o nÃ³ lÃ­der e redirecionar as requisiÃ§Ãµes para ele;
- Garantir que apenas apÃ³s o commit majoritÃ¡rio as operaÃ§Ãµes sejam consideradas concluÃ­das;
- Manter a consistÃªncia dos dados entre todos os nÃ³s mesmo apÃ³s falhas simuladas.

Os logs esperados incluem mensagens como:
```bash
ğŸš« Este nÃ³ nÃ£o Ã© o lÃ­der. Redirecionando para o lÃ­der...
ğŸ”„ Redirecionando requisiÃ§Ã£o para o lÃ­der: http://avatar-node1:8080/api/users
ğŸ’• Heartbeat enviado para propagaÃ§Ã£o de log.
ğŸ‰ SUCESSO! Log persistido em 3 nÃ³s (Maioria alcanÃ§ada: 2).
```

## 6. CenÃ¡rios de Falha

AlÃ©m dos testes de carga, tambÃ©m foram simuladas situaÃ§Ãµes de falha:

- InterrupÃ§Ã£o do lÃ­der durante commits ativos;
- LatÃªncia de rede e perda de pacotes entre os nÃ³s;
- CondiÃ§Ãµes de concorrÃªncia extrema, com mÃºltiplas requisiÃ§Ãµes simultÃ¢neas em nÃ³s diferentes.

Nesses casos, o sistema deve:

- Eleger automaticamente um novo lÃ­der (Raft reconfigura o cluster);
- Retornar respostas HTTP adequadas (ex: 503 Service Unavailable durante eleiÃ§Ã£o);
- Garantir que nenhum dado seja perdido apÃ³s a reconexÃ£o.

## 7. MÃ©tricas Avaliadas

| MÃ©trica | DescriÃ§Ã£o |
|---------|------------|
| `Tempo mÃ©dio de resposta (ms)` | Mede a latÃªncia entre requisiÃ§Ã£o e resposta final. |
| `Throughput (req/s)` | NÃºmero de requisiÃ§Ãµes processadas por segundo. |
| `Taxa de sucesso (%)` | Percentual de requisiÃ§Ãµes concluÃ­das sem erro. |
---
